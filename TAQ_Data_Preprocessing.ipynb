{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02443513-8a5e-4d87-8af7-ee986567e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Change path to\n",
    "TAQ_MS_FILE = \"/home/asyed/Documents/Spring 2024/MS&E 349/Volume Prediction/TAQ_Millisecond_AAPL_2023.csv\"\n",
    "chunksize = 2**16  # Size of chunks to read at a time\n",
    "\n",
    "#Converters to ensure data types are correctly handled\n",
    "converters = {\n",
    "    'SIZE': np.int64,\n",
    "    'PRICE': np.float64,\n",
    "    'TR_CORR': np.int64,\n",
    "    'TR_SEQNUM': np.int64,\n",
    "    'TR_ID': np.int64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdab20db-5540-4fdd-be4d-e48ec55e8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []  #List to hold processed data from each chunk\n",
    "\n",
    "#Read and process the full-sized data file\n",
    "for chunk in pd.read_csv(TAQ_MS_FILE, chunksize=chunksize, converters=converters):\n",
    "    #Create a 'datetime' column by combining 'DATE' and 'TIME_M'\n",
    "    chunk['datetime'] = pd.to_datetime(chunk['DATE'] + ' ' + chunk['TIME_M'])\n",
    "    chunk.set_index('datetime', inplace=True)  #'datetime' is now our index\n",
    "    chunk['TURNOVER'] = chunk['SIZE'] * chunk['PRICE'] #Turnover for each transaction\n",
    "    #Aggregate data by hourly intervals\n",
    "    grouped = chunk.groupby(pd.Grouper(freq='1h')).agg(\n",
    "        TURNOVER=pd.NamedAgg(column=\"TURNOVER\", aggfunc=\"sum\")  #Aggregate turnover\n",
    "    )\n",
    "    chunks.append(grouped)  \n",
    "\n",
    "\n",
    "hourly_data = pd.concat(chunks)\n",
    "#Remove duplicates by summing turnovers for each hour again \n",
    "hourly_data = hourly_data.groupby(hourly_data.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9f26c7-da9d-4068-a825-fbba5c8688f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling median of the trailing 30 days of turnovers\n",
    "hourly_data['date'] = hourly_data.index.date  # Extract date from datetime index\n",
    "daily_turnover = hourly_data.groupby('date')['TURNOVER'].sum()  # Sum turnovers by day\n",
    "rolling_median_30d = daily_turnover.rolling(window=30).median()  # Rolling median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8448f73c-12f4-4d62-89b0-d18cade03b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fn normalizes hourly turnovers by the rolling median of the preceding 30 trading days\n",
    "def normalize_turnovers(df, rolling_median):\n",
    "    normalized_turnovers = []\n",
    "    for date, group in df.groupby(df.index.date):\n",
    "        if date in rolling_median.index:\n",
    "            median_value = rolling_median.loc[date]\n",
    "            normalized_turnovers.extend(group['TURNOVER'] / median_value)\n",
    "        else:\n",
    "            normalized_turnovers.extend([np.nan] * len(group))\n",
    "    return pd.Series(normalized_turnovers, index=df.index)\n",
    "\n",
    "normalized_turnovers = normalize_turnovers(hourly_data, rolling_median_30d)\n",
    "hourly_data['Normalized_TURNOVER'] = normalized_turnovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d654a310-292d-4535-951f-2c4062e13647",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data = hourly_data.dropna(subset=['Normalized_TURNOVER'])\n",
    "hourly_data.drop(columns=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0d0999-8cc5-476d-9223-61eaf0813afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First non-zero turnover entry:\n",
      "TURNOVER               1.103893e+09\n",
      "Normalized_TURNOVER    1.455840e-01\n",
      "Name: 2023-02-01 09:00:00, dtype: float64\n",
      "All non-zero turnovers for 2023-02-01:\n",
      "                         TURNOVER  Normalized_TURNOVER\n",
      "datetime                                              \n",
      "2023-02-01 09:00:00  1.103893e+09             0.145584\n",
      "2023-02-01 10:00:00  1.275860e+09             0.168263\n",
      "2023-02-01 11:00:00  7.645183e+08             0.100826\n",
      "2023-02-01 12:00:00  8.913491e+08             0.117553\n",
      "2023-02-01 13:00:00  7.059671e+08             0.093105\n",
      "2023-02-01 14:00:00  2.150677e+09             0.283636\n",
      "2023-02-01 15:00:00  2.710917e+09             0.357522\n",
      "Normalized hourly turnover data saved to /home/asyed/Documents/Spring 2024/MS&E 349/Volume Prediction/TAQ_Hourly_AAPL_2023_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "#Just a sanity check. Let's find the first row where TURNOVER isn't zero\n",
    "first_non_zero_turnover = hourly_data[hourly_data['TURNOVER'] != 0].iloc[0]\n",
    "first_non_zero_date = first_non_zero_turnover.name.date()\n",
    "\n",
    "#Find and print all turnovers for the first non-zero turnover date (so all the trading hours for that day)\n",
    "non_zero_turnovers_on_date = hourly_data[(hourly_data.index.date == first_non_zero_date) & (hourly_data['TURNOVER'] != 0)]\n",
    "\n",
    "print(\"First non-zero turnover entry:\")\n",
    "print(first_non_zero_turnover)\n",
    "\n",
    "print(f\"All non-zero turnovers for {first_non_zero_date}:\")\n",
    "print(non_zero_turnovers_on_date)\n",
    "\n",
    "#Helps to get the resulting data to as a new CSV file\n",
    "hourly_data.to_csv(\"/home/asyed/Documents/Spring 2024/MS&E 349/Volume Prediction/TAQ_Hourly_AAPL_2023_normalized.csv\")\n",
    "\n",
    "print(f\"Normalized hourly turnover data saved to /home/asyed/Documents/Spring 2024/MS&E 349/Volume Prediction/TAQ_Hourly_AAPL_2023_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7dfef-fb95-460d-ab14-9a8652540a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af85d7-add8-4f13-8350-5a4d9003677b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
