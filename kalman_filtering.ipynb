{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ea664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data/TAQ_30Min_AAPL_2023_normalized.csv\")\n",
    "df.index = df.datetime\n",
    "df[\"Log_Turnover\"] = np.log(df[\"Normalized_TURNOVER\"])\n",
    "T = 13\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, pi, Sigma, a_eta, a_mu, sigma_eta_sq, sigma_mu_sq, r, phi):\n",
    "        # pi and Sigma go into $x_t ~ \\mathcal{N}(\\pi_t, \\Sigma_t)$\n",
    "        self.pi = pi\n",
    "        self.Sigma = Sigma\n",
    "        # a_eta and a_mu define the state transition matrix A = [a_eta 0; 0 a_mu]\n",
    "        self.a_eta = a_eta\n",
    "        self.a_mu = a_mu\n",
    "        # sigma_eta and sigma_mu define the covariance matrix Q = [sigma_eta^2 0; 0 sigma_mu^2]\n",
    "        # for the Gaussian noise in the state transition w_t ~ \\mathcal{N}(0, Q_t)\n",
    "        self.sigma_eta_sq = sigma_eta_sq\n",
    "        self.sigma_mu_sq = sigma_mu_sq\n",
    "        # r goes into v_t ~ \\mathcal{N}(0,r) where v_t is the noise in observation t\n",
    "        self.r = r\n",
    "        # phi is the seasonality parameter.\n",
    "        # It's a vector in $\\mathbb{R}^T$ where T is the number of intraday observations in a day\n",
    "        self.phi = phi\n",
    "    \n",
    "    def A(self):\n",
    "        return np.vstack([np.hstack([np.eye(T)*self.a_eta, np.zeros((T,T))]),\n",
    "                          np.hstack([np.zeros((T,T)), np.eye(T)*self.a_mu])])\n",
    "    \n",
    "    def Q(self):\n",
    "        return np.vstack([np.hstack([np.eye(T)*self.sigma_eta_sq, np.zeros((T,T))]),\n",
    "                          np.hstack([np.zeros((T,T)), np.eye(T)*self.sigma_mu_sq])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.hstack([np.eye(T), np.eye(T)])\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ca773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "theta = Params(np.zeros(2), np.identity(2)*0.5, 1.0, 1.0, 0.0025, 0.0025, 0.0005, np.array([0.6, 0.25, 0.0, -0.15, -0.3, -0.45, -0.5, -0.6, -0.5, -0.25, -0.3, -0.1, 0.4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9481a",
   "metadata": {},
   "source": [
    "## Expectation maximization\n",
    "In this step we want to predict $x_\\tau = [\\eta_\\tau\\ \\mu_\\tau]^\\top \\in \\mathbb{R}^2$ which is the hidden state vector. The variables $\\eta_\\tau$ and $\\mu_\\tau$ are the daily average and intraday dynamic part of the log volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6fd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filtering(x_hat_tau, y_tau_plus, Sigma_tau_tau, params):\n",
    "    A = params.A()\n",
    "    x_hat_tau_plus = A @ x_hat_tau # predict mean\n",
    "    Sigma_tau_plus = A @ Sigma_tau_tau @ A.T + params.Q() # predict covariance\n",
    "    \n",
    "    # compute Kalman gain\n",
    "    K_tau_plus = Sigma_tau_plus @ C.T @ np.linalg.inv(C @ Sigma_tau_plus @ C.T + params.r)\n",
    "    \n",
    "    # correct conditional mean\n",
    "    x_hat_next = x_hat_tau_plus + K_tau_plus @ (y_tau_plus - params.phi - C@x_hat_tau_plus)\n",
    "    Sigma_next = Sigma_tau_plus - K_tau_plus @ C @ Sigma_tau_plus\n",
    "    #print(\"x_hat_next\", x_hat_next.shape, \"Sigma_next\", Sigma_next.shape)\n",
    "    return x_hat_next, Sigma_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up and run a dimensional test\n",
    "y_1 = df.head(T)[\"Log_Turnover\"]\n",
    "x_1 = np.reshape(np.array([y_1/2, y_1/2]), 2*T)\n",
    "Sigma_1 = np.eye(2*T)\n",
    "x_plus, Sigma_plus = kalman_filtering(x_1, y_1, Sigma_1, theta)\n",
    "print(\"Shape should be {}: x.shape = {}\".format(2*T, x_plus.shape))\n",
    "print(\"Shape should be {} x {}: Sigma.shape = {}\".format(2*T, 2*T, Sigma_plus.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_smoothing(x_t, ys, Sigma_t, params):\n",
    "    # this uses the outputs from the filtering algorithm\n",
    "    # NOTE THAT x_t is a shorthand in the next few lines for x_{t|t} and Sigma_t := Sigma_{t|t}\n",
    "    N = ys.shape[0]\n",
    "    x_ts = []\n",
    "    Sigma_ts = []\n",
    "    \n",
    "    # this is an unsightly way to code it but I think it makes more sense\n",
    "    for t in range(0, N):\n",
    "        x_t, Sigma_t = kalman_filtering(x_t, ys[t,:], Sigma_t, params)\n",
    "        x_ts.append(x_t)\n",
    "        Sigma_ts.append(Sigma_t)\n",
    "        \n",
    "    x_N, Sigma_N = x_ts[-1], Sigma_ts[-1]\n",
    "    # Now we have x_{N|N}, Sigma_{N|N}\n",
    "    \n",
    "    x_tau_n = x_N # this is the initialization of x_{t+1|N} and Sigma_{t+1|N}\n",
    "    Sigma_tau_n = Sigma_N\n",
    "    \n",
    "    for t in range(N-1, 0, -1):\n",
    "        A = params.A()\n",
    "        # in here, Sigma_ts[t-1] is Sigma_{t|t} because of 0-indexing\n",
    "        Sigma_tau_plus = A @ Sigma_ts[t-1] @ A.T + params.Q()\n",
    "        x_hat_tau_plus = A @ x_ts[t-1]\n",
    "        \n",
    "        Lt = Sigma_ts[t-1] @ A.T @ np.linalg.inv(Sigma_tau_plus)\n",
    "        x_tau_n = x_ts[t-1] + Lt @ (x_tau_n - x_hat_tau_plus)\n",
    "        Sigma_tau_n = Sigma_ts[t-1] + Lt @ (Sigma_tau_n - Sigma_tau_plus) @ Lt.T\n",
    "    return x_tau_n, Sigma_tau_n # this is x_{t|N} and Sigma_{t|N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = df[\"Log_Turnover\"].to_numpy()\n",
    "ys = np.reshape(ys, (int(ys.shape[0]/T), T))\n",
    "ys.shape\n",
    "N_train = 110 # about half the data\n",
    "x_tau_n, Sigma_tau_n = kalman_smoothing(x_1, ys[0:N_train,:], Sigma_1, theta)\n",
    "# dimensional check again\n",
    "print(x_tau_n.shape)\n",
    "print(Sigma_tau_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em(params_0; maxsteps=10, tol=1e-3)\n",
    "    i = 0; err = np.Inf\n",
    "    while i < maxsteps or err < tol:\n",
    "        # Iteratively do it\n",
    "        for tau in range(N-1, 0, -1):\n",
    "            # TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4b1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d36128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
