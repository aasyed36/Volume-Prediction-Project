{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b33c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data/TAQ_30Min_AAPL_2023_normalized.csv\")\n",
    "df.index = df.datetime\n",
    "df[\"Log_Turnover\"] = np.log(df[\"Normalized_TURNOVER\"])\n",
    "T = 13\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, pi, Sigma, a_eta, a_mu, sigma_eta_sq, sigma_mu_sq, r, phi, T=1):\n",
    "        # pi and Sigma go into $x_t ~ \\mathcal{N}(\\pi_t, \\Sigma_t)$\n",
    "        self.pi = pi\n",
    "        self.Sigma = Sigma\n",
    "        # a_eta and a_mu define the state transition matrix A = [a_eta 0; 0 a_mu]\n",
    "        self.a_eta = a_eta\n",
    "        self.a_mu = a_mu\n",
    "        # sigma_eta and sigma_mu define the covariance matrix Q = [sigma_eta^2 0; 0 sigma_mu^2]\n",
    "        # for the Gaussian noise in the state transition w_t ~ \\mathcal{N}(0, Q_t)\n",
    "        self.sigma_eta_sq = sigma_eta_sq\n",
    "        self.sigma_mu_sq = sigma_mu_sq\n",
    "        # r goes into v_t ~ \\mathcal{N}(0,r) where v_t is the noise in observation t\n",
    "        self.r = r\n",
    "        # phi is the seasonality parameter.\n",
    "        # It's a vector in $\\mathbb{R}^T$ where T is the number of intraday observations in a day\n",
    "        self.phi = phi\n",
    "        self.T = T\n",
    "    \n",
    "    def A(self, tau):\n",
    "        a1 = 1.0\n",
    "        a2 = 1.0\n",
    "        T = self.T\n",
    "        if tau % T == 0: # tau = kT for some integer K, T is the # of observations in a day\n",
    "            a1 = self.a_eta\n",
    "            a2 = self.a_mu\n",
    "        return np.vstack([np.hstack([np.eye(T)*a1, np.zeros((T,T))]),\n",
    "                         np.hstack([np.zeros((T,T)), np.eye(T)*a2])])\n",
    "    \n",
    "    def Q(self, tau):\n",
    "        a1 = 0.0\n",
    "        a2 = 0.0\n",
    "        T = self.T\n",
    "        if tau % T == 0: # tau = kT for some integer K, T is the # of observations in a day\n",
    "            a1 = self.sigma_eta_sq\n",
    "            a2 = self.sigma_mu_sq\n",
    "        return np.vstack([np.hstack([np.eye(T)*a1, np.zeros((T,T))]),\n",
    "                          np.hstack([np.zeros((T,T)), np.eye(T)*a2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02818a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.hstack([np.eye(T), np.eye(T)])\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "theta = Params(np.zeros(2), np.identity(2)*0.5, 1.0, 1.0, 0.0025, 0.0025, 0.0005, np.array([0.6, 0.25, 0.0, -0.15, -0.3, -0.45, -0.5, -0.6, -0.5, -0.25, -0.3, -0.1, 0.4]), T=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76598271",
   "metadata": {},
   "source": [
    "## Expectation maximization\n",
    "In this step we want to predict $x_\\tau = [\\eta_\\tau\\ \\mu_\\tau]^\\top \\in \\mathbb{R}^2$ which is the hidden state vector. The variables $\\eta_\\tau$ and $\\mu_\\tau$ are the daily average and intraday dynamic part of the log volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filtering(tau, x_hat_tau, y_tau_plus, Sigma_tau_tau, params):\n",
    "    A = params.A(tau)\n",
    "    x_hat_tau_plus = A @ x_hat_tau # predict mean\n",
    "    Sigma_tau_plus = A @ Sigma_tau_tau @ A.T + params.Q(tau) # predict covariance\n",
    "    \n",
    "    # compute Kalman gain\n",
    "    K_tau_plus = Sigma_tau_plus @ C.T @ np.linalg.inv(C @ Sigma_tau_plus @ C.T + params.r)\n",
    "    \n",
    "    # correct conditional mean\n",
    "    x_hat_next = x_hat_tau_plus + K_tau_plus @ (y_tau_plus - params.phi - C@x_hat_tau_plus)\n",
    "    Sigma_next = Sigma_tau_plus - K_tau_plus @ C @ Sigma_tau_plus\n",
    "    #print(\"x_hat_next\", x_hat_next.shape, \"Sigma_next\", Sigma_next.shape)\n",
    "    return x_hat_next, Sigma_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up and run a dimensional test\n",
    "y_1 = df.head(T)[\"Log_Turnover\"]\n",
    "x_1 = np.reshape(np.array([y_1/2, y_1/2]), 2*T)\n",
    "Sigma_1 = np.eye(2*T)\n",
    "x_plus, Sigma_plus = kalman_filtering(1, x_1, y_1, Sigma_1, theta)\n",
    "print(\"Shape should be {}: x.shape = {}\".format(2*T, x_plus.shape))\n",
    "print(\"Shape should be {} x {}: Sigma.shape = {}\".format(2*T, 2*T, Sigma_plus.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e65e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_smoothing(x_t, ys, Sigma_t, params):\n",
    "    # this uses the outputs from the filtering algorithm\n",
    "    # NOTE THAT x_t is a shorthand in the next few lines for x_{t|t} and Sigma_t := Sigma_{t|t}\n",
    "    N = ys.shape[0]\n",
    "    x_ts = []\n",
    "    Sigma_ts = []\n",
    "    \n",
    "    # this is an unsightly way to code it but I think it makes more sense\n",
    "    for t in range(0, N):\n",
    "        x_t, Sigma_t = kalman_filtering(t, x_t, ys[t], Sigma_t, params)\n",
    "        x_ts.append(x_t)\n",
    "        Sigma_ts.append(Sigma_t)\n",
    "        \n",
    "    x_N, Sigma_N = x_ts[-1], Sigma_ts[-1]\n",
    "    # Now we have x_{N|N}, Sigma_{N|N}\n",
    "    \n",
    "    x_tau_n = x_N # this is the initialization of x_{t+1|N} and Sigma_{t+1|N}\n",
    "    Sigma_tau_n = Sigma_N\n",
    "    Lt = np.zeros_like(Sigma_t)\n",
    "    \n",
    "    for t in range(N-1, 0, -1):\n",
    "        A = params.A(t)\n",
    "        # in here, Sigma_ts[t-1] is Sigma_{t|t} because of 0-indexing\n",
    "        Sigma_tau_plus = A @ Sigma_ts[t-1] @ A.T + params.Q(t)\n",
    "        x_hat_tau_plus = A @ x_ts[t-1]\n",
    "        \n",
    "        Lt = Sigma_ts[t-1] @ A.T @ np.linalg.inv(Sigma_tau_plus)\n",
    "        x_tau_n = x_ts[t-1] + Lt @ (x_tau_n - x_hat_tau_plus)\n",
    "        Sigma_tau_n = Sigma_ts[t-1] + Lt @ (Sigma_tau_n - Sigma_tau_plus) @ Lt.T\n",
    "    return x_tau_n, Sigma_tau_n, Lt, x_ts, Sigma_ts # this is x_{t|N} and Sigma_{t|N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1387db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = df[\"Log_Turnover\"].to_numpy()\n",
    "#ys = np.reshape(ys, (int(ys.shape[0]/T), T)) # reshape ys to (N_days, T)\n",
    "\n",
    "N_train = T*10\n",
    "\n",
    "x_tau_n, Sigma_tau_n, _, _, _ = kalman_smoothing(x_1, ys[0:N_train], Sigma_1, theta)\n",
    "# dimensional check again\n",
    "print(x_tau_n.shape)\n",
    "print(Sigma_tau_n.shape)\n",
    "plt.imshow(Sigma_tau_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(params1, params2):\n",
    "    err = np.mean(np.abs(params1.pi - params2.pi)) + np.mean(np.abs(params1.Sigma - params2.Sigma)) + \\\n",
    "          np.abs(params1.a_eta - params2.a_eta) + np.abs(params1.a_mu - params2.a_mu) + \\\n",
    "          np.abs(params1.sigma_eta_sq - params2.sigma_eta_sq) + \\\n",
    "          np.abs(params1.sigma_mu_sq - params2.sigma_mu_sq) + \\\n",
    "          np.abs(params1.r - params2.r) + np.mean(np.abs(params1.phi - params2.phi))\n",
    "    return err/8.0 # since there are 8 terms\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_matrices(Ps):\n",
    "    result = np.zeros_like(Ps[0])\n",
    "    for Pi in Ps:\n",
    "        result += Pi\n",
    "    return result\n",
    "\n",
    "def em(x_tau, ys, Sigma_tau, params, maxsteps=10, tol=1e-1):\n",
    "    i = 0; err = np.Inf\n",
    "    N = ys.shape[0]\n",
    "    N_days = int(N/T)\n",
    "    \n",
    "    while i < maxsteps or err < tol:\n",
    "        \n",
    "        Ps = [] # this is an array of P_t in REVERSE order\n",
    "        P_minuses = [] # this is an array of P_{t|t-1} in REVERSE order, e.g. P_{N|N-1} is first and P_{1|0} is last\n",
    "        xs = []\n",
    "        \n",
    "        Sigma_tau_minus_N = Sigma_tau # IDK how to initialize this\n",
    "        for tau in range(N-1, -1, -1):\n",
    "            x_tau_n, Sigma_tau_n, L_tau, x_ts, Sigma_ts = kalman_smoothing(x_tau, ys[0:tau+1], Sigma_tau, params)\n",
    "            x_tau = x_tau_n\n",
    "            P_tau = Sigma_tau_n + x_tau_n @ x_tau_n.T\n",
    "            \n",
    "            x_tau_minus_n, _, L_tau_minus, _, _ = kalman_smoothing(x_tau, ys[0:tau], Sigma_tau, params)\n",
    "            # This is line 7 of Algorithm 3 which computes Sigma_{tau, tau-1|N}\n",
    "            # Note that Sigma_{tau, tau-1|N} has a dependency on Sigma_{tau+1, tau|N} which makes sense except\n",
    "            # we do not know what to initialize it to\n",
    "            Sigma_tau_minus_N = Sigma_ts[tau-1] @ L_tau_minus.T + \\\n",
    "                                L_tau @ (Sigma_tau_minus_N - params.A(tau) @ Sigma_ts[tau]) @ L_tau_minus.T\n",
    "            P_tau_minus = Sigma_tau_minus_N + x_tau_n @ x_tau_minus_n\n",
    "            \n",
    "            xs.append(x_tau)\n",
    "            Ps.append(P_tau)\n",
    "            P_minuses.append(P_tau_minus)\n",
    "        Ps.reverse()\n",
    "        P_minuses.reverse()\n",
    "        print(\"first step done\")\n",
    "        \n",
    "        # now we have a list of P_t and P_{t|t-1}\n",
    "        pi = x_tau # equation 17\n",
    "        Sigma = Ps[-1] - x_tau @ x_tau.T # equation 18\n",
    "\n",
    "        P_sum = sum_matrices([Ps[T*i + 1] for i in range(N_days)]) # for equation 19\n",
    "        P_minus_sum = sum_matrices([P_minuses[T*i + 1] for i in range(N_days)]) # for equation 19\n",
    "        a_eta = P_minus_sum[0:T, 0:T] @ np.linalg.inv(P_sum[0:T,0:T])\n",
    "        \n",
    "        P_sum2 = sum_matrices([Ps[i] for i in range(2, N)]) # for equation 20\n",
    "        P_minus_sum2 = sum_matrices([P_minuses[i] for i in range(1, N-1)]) # for equation 20\n",
    "        a_mu = P_minus_sum2[T+1:, T+1:] @ np.linalg.inv(P_sum2[T+1:, T+1:])\n",
    "        \n",
    "        sigma_eta_sq = np.zeros((T,T)) # equation 21\n",
    "        for i in range(N_days):\n",
    "            t = i*T+1\n",
    "            sigma_eta_sq += (Ps[t] + a_eta**2.0 * Ps[t-1] - 2.0 * a_eta * P_minuses[t])[0:T,0:T]\n",
    "        sigma_eta_sq *= 1.0/(N_days + 1.0)\n",
    "        \n",
    "        sigma_mu_sq = np.zeros((T,T)) # equation 22\n",
    "        for t in range(2, N):\n",
    "            sigma_mu_sq = (Ps[t] + a_mu**2.0 * Ps[t-1] - 2.0 * a_mu * P_minuses[t])[T+1:, T+1:]\n",
    "        sigma_mu_sq *= 1.0/(N - 1.0)\n",
    "        \n",
    "        r = 0.0\n",
    "        for t in range(N): # equation 23, probably\n",
    "            r += ys[t]**2 + np.sum(P[t]) - 2.0*ys[t] * np.sum(xs[t]) + \\\n",
    "                (params.phi[t%T])**2.0 - 2.0 * ys[t] * params.phi[t%T] + \\\n",
    "                2.0*params.phi[t%T] * np.sum(xs[t])\n",
    "        r *= 1.0/N\n",
    "        \n",
    "        phi = np.zeros(N_days)\n",
    "        for i in range(N_days):\n",
    "            phi += ys[i*T:(i+1)*T] - C@xs[t]\n",
    "        phi /= 1.0/N_days\n",
    "        print(\"second step done\")\n",
    "        params1 = Params(pi, Sigma, a_eta, a_mu, sigma_eta_sq, sigma_mu_sq, r, phi)\n",
    "        err = compare(params, params1)\n",
    "        params = params1\n",
    "        print(i, err)\n",
    "        \n",
    "    return params\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "em(x_1, ys[1:N_train], Sigma_1, theta, maxsteps=10, tol=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff393255",
   "metadata": {},
   "source": [
    "## Test Kalman filter with given params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df[\"Log_Turnover\"].size\n",
    "x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = df.iloc[0:T][\"Log_Turnover\"]\n",
    "x_t = np.reshape(np.array([y_t/2, y_t/2]), 2*T)\n",
    "xs = [x_t,]\n",
    "\n",
    "Sigma_t = np.identity(2*T)\n",
    "sigmas = [Sigma_t,]\n",
    "\n",
    "ys = [y_t]\n",
    "\n",
    "for i in range(int(N/T)):\n",
    "    y_t = df.iloc[i*T:(i+1)*T][\"Log_Turnover\"]\n",
    "    x_plus, Sigma_plus = kalman_filtering(i, x_t, y_t, Sigma_t, theta)\n",
    "    xs.append(x_plus)\n",
    "    sigmas.append(Sigma_plus)\n",
    "    ys.append(C@x_plus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = [np.mean(np.square(ys[i] - df.iloc[i*T:(i+1)*T][\"Log_Turnover\"])) for i in range(int(N/T))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53881f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(errs, label=\"Prediction error\")\n",
    "plt.xlabel(\"Day of year\"); plt.ylabel(\"MSE error\")\n",
    "plt.legend()\n",
    "plt.savefig(\"kalman_errors_year.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(np.exp(ys[-1]),label=\"Predicted\", linestyle=\"--\", color=\"cornflowerblue\")\n",
    "plt.plot(np.exp(df.iloc[-T:][\"Log_Turnover\"]), label=\"True\", color=\"black\")\n",
    "\n",
    "daily_labels = [\"9:30\", \"10:30\", \"11:30\", \"12:30\", \"13:30\", \"14:30\", \"15:30\",]\n",
    "plt.xticks(ticks=range(0, N_day, 2), labels=daily_labels)\n",
    "plt.legend(); plt.ylabel(\"Normalized turnover\")\n",
    "plt.savefig(\"kalman_prediction.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8520b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.square(ys[-1] - df.iloc[-T:][\"Log_Turnover\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b90de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
