{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c28f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "df = pd.read_csv(\"data/TAQ_30Min_AAPL_2023_normalized.csv\")\n",
    "df.index = df.datetime\n",
    "df[\"Log_Turnover\"] = np.log(df[\"Normalized_TURNOVER\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3f96f",
   "metadata": {},
   "source": [
    "## Preliminary: QQ plot\n",
    "Since the Kalman filter paper has one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_nolog = qqplot(df[\"Normalized_TURNOVER\"], line=\"s\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"nolog_qqplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123351d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_log = qqplot(np.log(df[\"Normalized_TURNOVER\"]), line=\"s\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"log_qqplot.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427797b2",
   "metadata": {},
   "source": [
    "## Define parameter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, pi, Sigma, a_eta, a_mu, sigma_eta_sq, sigma_mu_sq, r, phi):\n",
    "        # pi and Sigma go into $x_t ~ \\mathcal{N}(\\pi_t, \\Sigma_t)$\n",
    "        self.pi = pi\n",
    "        self.Sigma = Sigma\n",
    "        # a_eta and a_mu define the state transition matrix A = [a_eta 0; 0 a_mu]\n",
    "        self.a_eta = a_eta\n",
    "        self.a_mu = a_mu\n",
    "        # sigma_eta and sigma_mu define the covariance matrix Q = [sigma_eta^2 0; 0 sigma_mu^2]\n",
    "        # for the Gaussian noise in the state transition w_t ~ \\mathcal{N}(0, Q_t)\n",
    "        self.sigma_eta_sq = sigma_eta_sq\n",
    "        self.sigma_mu_sq = sigma_mu_sq\n",
    "        # r goes into v_t ~ \\mathcal{N}(0,r) where v_t is the noise in observation t\n",
    "        self.r = r\n",
    "        # phi is the seasonality parameter.\n",
    "        # It's a vector in $\\mathbb{R}^T$ where T is the number of intraday observations in a day\n",
    "        self.phi = phi\n",
    "        \n",
    "    def A(self, tau):\n",
    "        a1 = 1.0\n",
    "        a2 = 1.0\n",
    "        if tau % 13 == 0: # tau = kT for some integer K, T is the # of observations in a day\n",
    "            a1 = self.a_eta\n",
    "            a2 = self.a_mu\n",
    "        return np.array([[a1, 0.0], [0.0, a2]])\n",
    "    \n",
    "    def Q(self, tau):\n",
    "        a1 = 0.0\n",
    "        a2 = 0.0\n",
    "        if tau % 13 == 0: # tau = kT for some integer K, T is the # of observations in a day\n",
    "            a1 = self.sigma_eta_sq\n",
    "            a2 = self.sigma_mu_sq\n",
    "        return np.array([[a1, 0.0], [0.0, a2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.ones((1,2))\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e0e6d",
   "metadata": {},
   "source": [
    "## Kalman filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10871bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization, I got this from the Kalman filtering paper\n",
    "theta = Params(np.zeros(2), np.identity(2)*0.5, 1.0, 1.0, 0.0025, 0.0025, 0.0005, np.array([0.6, 0.25, 0.0, -0.15, -0.3, -0.45, -0.5, -0.6, -0.5, -0.25, -0.3, -0.1, 0.4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filtering(tau, x_hat_tau, y_tau_plus, Sigma_tau_tau, params):\n",
    "    A = params.A(tau)\n",
    "    x_hat_tau_plus = A @ x_hat_tau # predict mean\n",
    "    Sigma_tau_plus = A @ Sigma_tau_tau @ A.T + params.Q(tau) # predict covariance\n",
    "    \n",
    "    # compute Kalman gain\n",
    "    K_tau_plus = Sigma_tau_plus @ C.T @ np.linalg.inv(C @ Sigma_tau_plus @ C.T + params.r)\n",
    "    \n",
    "    # correct conditional mean\n",
    "    x_hat_next = x_hat_tau_plus + K_tau_plus @ (y_tau_plus - params.phi[tau%13] - C@x_hat_tau_plus)\n",
    "    Sigma_next = Sigma_tau_plus - K_tau_plus @ C @ Sigma_tau_plus\n",
    "    #print(\"x_hat_next\", x_hat_next.shape, \"Sigma_next\", Sigma_next.shape)\n",
    "    return x_hat_next, Sigma_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up and run a dimensional test\n",
    "y_1 = df.head(1)[\"Log_Turnover\"]\n",
    "x_1 = np.reshape(np.array([y_1/2, y_1/2]), 2)\n",
    "Sigma_1 = np.eye(2)\n",
    "x_plus, Sigma_plus = kalman_filtering(1, x_1, y_1, Sigma_1, theta)\n",
    "print(\"Shape should be {}: x.shape = {}\".format(2, x_plus.shape))\n",
    "print(\"Shape should be {} x {}: Sigma.shape = {}\".format(2, 2, Sigma_plus.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d765c8",
   "metadata": {},
   "source": [
    "## Kalman smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b672b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_smoothing(x_t, ys, Sigma_t, params):\n",
    "    # this uses the outputs from the filtering algorithm\n",
    "    # NOTE THAT x_t is a shorthand in the next few lines for x_{t|t} and Sigma_t := Sigma_{t|t}\n",
    "    N = ys.shape[0]\n",
    "    x_ts = []\n",
    "    Sigma_ts = []\n",
    "    \n",
    "    # this is an unsightly way to code it but I think it makes more sense\n",
    "    for t in range(0, N):\n",
    "        x_t, Sigma_t = kalman_filtering(t, x_t, ys[t-1], Sigma_t, params)\n",
    "        x_ts.append(x_t)\n",
    "        Sigma_ts.append(Sigma_t)\n",
    "        \n",
    "    x_N, Sigma_N = x_ts[-1], Sigma_ts[-1]\n",
    "    # Now we have x_{N|N}, Sigma_{N|N}\n",
    "    \n",
    "    x_tau_n = x_N # this is the initialization of x_{t+1|N} and Sigma_{t+1|N}\n",
    "    Sigma_tau_n = Sigma_N\n",
    "    Lt = np.zeros_like(Sigma_t)\n",
    "    \n",
    "    for t in range(N-1, 0, -1):\n",
    "        A = params.A(t)\n",
    "        # in here, Sigma_ts[t-1] is Sigma_{t|t} because of 0-indexing\n",
    "        Sigma_tau_plus = A @ Sigma_ts[t-1] @ A.T + params.Q(t)\n",
    "        x_hat_tau_plus = A @ x_ts[t-1]\n",
    "        \n",
    "        Lt = Sigma_ts[t-1] @ A.T @ np.linalg.inv(Sigma_tau_plus)\n",
    "        x_tau_n = x_ts[t-1] + Lt @ (x_tau_n - x_hat_tau_plus)\n",
    "        Sigma_tau_n = Sigma_ts[t-1] + Lt @ (Sigma_tau_n - Sigma_tau_plus) @ Lt.T\n",
    "    return np.reshape(x_tau_n, (2,1)), Sigma_tau_n, Lt, x_ts, Sigma_ts # this is x_{t|N} and Sigma_{t|N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718901a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = df[\"Log_Turnover\"].to_numpy()\n",
    "#ys = np.reshape(ys, (int(ys.shape[0]/T), T)) # reshape ys to (N_days, T)\n",
    "\n",
    "N_train = 50\n",
    "\n",
    "x_tau_n, Sigma_tau_n, _, _, _ = kalman_smoothing(x_1, ys[0:N_train], Sigma_1, theta)\n",
    "# dimensional check again\n",
    "print(x_tau_n.shape)\n",
    "print(Sigma_tau_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a708d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(params1, params2):\n",
    "    err = np.mean(np.abs(params1.pi - params2.pi)) + np.mean(np.abs(params1.Sigma - params2.Sigma)) + \\\n",
    "          np.abs(params1.a_eta - params2.a_eta) + np.abs(params1.a_mu - params2.a_mu) + \\\n",
    "          np.abs(params1.sigma_eta_sq - params2.sigma_eta_sq) + \\\n",
    "          np.abs(params1.sigma_mu_sq - params2.sigma_mu_sq) + \\\n",
    "          np.abs(params1.r - params2.r) + np.mean(np.abs(params1.phi - params2.phi))\n",
    "    return err/8.0 # since there are 8 terms\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248f035",
   "metadata": {},
   "source": [
    "## Expectation maximization\n",
    "In this step we want to predict $x_\\tau = [\\eta_\\tau\\ \\mu_\\tau]^\\top \\in \\mathbb{R}^2$ which is the hidden state vector. The variables $\\eta_\\tau$ and $\\mu_\\tau$ are the daily average and intraday dynamic part of the log volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_matrices(Ps):\n",
    "    result = np.zeros_like(Ps[0])\n",
    "    for Pi in Ps:\n",
    "        result += Pi\n",
    "    return result\n",
    "\n",
    "I = 13\n",
    "\n",
    "def em(x_1, ys, params, maxsteps=10, tol=1e-1):\n",
    "    step = 0; err = np.Inf\n",
    "    N = ys.shape[0]\n",
    "    N_days = int(N/I)\n",
    "    print(\"N = {}, N_days={}\".format(N, N_days))\n",
    "    \n",
    "    while step < maxsteps and err > tol:\n",
    "        \n",
    "        Ps = [] # this is an array of P_t in REVERSE order\n",
    "        P_minuses = [] # this is an array of P_{t|t-1} in REVERSE order, e.g. P_{N|N-1} is first and P_{1|0} is last\n",
    "        xs = []\n",
    "        x_tau = x_1\n",
    "        Sigma_tau = params.Sigma\n",
    "        Sigma_tau_minus_N = Sigma_tau # IDK how to initialize this\n",
    "        \n",
    "        for tau in range(N, 1, -1): # this is [N, N-1,...,2] because otherwise the indexing doesn't make sense for kalman smoothing\n",
    "            # this line is x_{tau|N}, Sigma_{tau|N}, L_tau and x_ts = list of x_{tau|tau}, Sigma_ts = list of Sigma_{tau|tau}\n",
    "            x_tau_n, Sigma_tau_n, L_tau, x_ts, Sigma_ts = kalman_smoothing(x_1, ys[0:tau], params.Sigma, params)\n",
    "            x_tau = x_tau_n # line 5\n",
    "            P_tau = Sigma_tau_n + x_tau_n @ x_tau_n.T # line 6\n",
    "            \n",
    "            # this line gets x_{tau-1|N}, Sigma-{tau-1|N} and L_{tau-1}\n",
    "            x_tau_minus_n, Sigma_tau_minus_N, L_tau_minus, _, _ = kalman_smoothing(x_1, ys[0:tau-1], params.Sigma, params)\n",
    "            # This is line 7 of Algorithm 3 which computes Sigma_{tau, tau-1|N}\n",
    "            # Note that Sigma_{tau, tau-1|N} has a dependency on Sigma_{tau+1, tau|N} which makes sense except\n",
    "            # we do not know what to initialize it to\n",
    "            Sigma_tau_minus_N = Sigma_ts[tau-1] @ L_tau_minus.T + \\\n",
    "                                L_tau @ (Sigma_tau_minus_N - params.A(tau) @ Sigma_ts[tau-1]) @ L_tau_minus.T\n",
    "            P_tau_minus = Sigma_tau_minus_N + x_tau_n @ x_tau_minus_n.T # line 8\n",
    "            \n",
    "            xs.append(x_tau)\n",
    "            Ps.append(P_tau)\n",
    "            P_minuses.append(P_tau_minus)\n",
    "        Ps.reverse()\n",
    "        P_minuses.reverse()\n",
    "        print(\"{} first step done {}\".format(step, len(Ps)))\n",
    "        \n",
    "        N = N - 1\n",
    "        # now we have a list of P_t and P_{t|t-1}\n",
    "        pi = x_tau # equation 17\n",
    "        Sigma = Ps[-1] - x_tau @ x_tau.T # equation 18\n",
    "        print(\"\\tpi, sigma = {}, {}\".format(pi, Sigma))\n",
    "        P_sum = sum_matrices([Ps[I*i + 1] for i in range(N_days)]) # for equation 19\n",
    "        P_minus_sum = sum_matrices([P_minuses[I*i + 1] for i in range(N_days)]) # for equation 19\n",
    "        a_eta = P_minus_sum[0,0] / P_sum[0,0]\n",
    "        \n",
    "        P_sum2 = sum_matrices([Ps[i] for i in range(2, N)]) # for equation 20\n",
    "        P_minus_sum2 = sum_matrices([P_minuses[i] for i in range(1, N-1)]) # for equation 20\n",
    "        a_mu = P_minus_sum2[1,1] / P_sum2[1,1]\n",
    "        \n",
    "        sigma_eta_sq = 0.0 # equation 21\n",
    "        print(\"\\ta_eta = {}, a_mu = {}\".format(a_eta, a_mu))\n",
    "        for i in range(N_days):\n",
    "            t = i*I+1\n",
    "            sigma_eta_sq += (Ps[t] + a_eta**2.0 * Ps[t-1] - 2.0 * a_eta * P_minuses[t-1])[0,0]\n",
    "        sigma_eta_sq /= (N_days - 1) # \n",
    "        \n",
    "        sigma_mu_sq = 0.0 # equation 22\n",
    "        for t in range(2, N):\n",
    "            sigma_mu_sq = (Ps[t] + a_mu**2.0 * Ps[t-1] - 2.0 * a_mu * P_minuses[t-1])[1,1]\n",
    "        sigma_mu_sq *= 1.0/(N - 1.0)\n",
    "        print(\"\\tsigma_eta_sq = {}, sigma_mu_sq = {}\".format(sigma_eta_sq, sigma_mu_sq))\n",
    "        r = 0.0\n",
    "        for t in range(N): # equation 23, probably\n",
    "            r += ys[t]**2 + np.sum(Ps[t]) - 2.0*ys[t] * np.sum(xs[t]) + \\\n",
    "                (params.phi[t%I])**2.0 - 2.0 * ys[t] * params.phi[t%I] + \\\n",
    "                2.0*params.phi[t%I] * np.sum(xs[t])\n",
    "        r /= N\n",
    "        \n",
    "        phi = np.zeros(13)\n",
    "        for i in range(N):\n",
    "            phi[i%I] += (ys[i:i+1] - C@xs[i])[0,0]\n",
    "        phi /= N_days\n",
    "        print(\"\\tr = {}, phi = {}\".format(r, phi))\n",
    "        print(\"{} second step done\".format(step))\n",
    "        \n",
    "        \n",
    "        params1 = Params(pi, Sigma, a_eta, a_mu, sigma_eta_sq, sigma_mu_sq, r, phi)\n",
    "        err = compare(params, params1)\n",
    "        params = params1\n",
    "        \n",
    "        print(\"{}, Error={}\".format(step, err))\n",
    "        step += 1\n",
    "        N += 1\n",
    "        \n",
    "    return params\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712c23a",
   "metadata": {},
   "source": [
    "## Class interface\n",
    "This does not do exactly what is requested but it is close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanPredictor:\n",
    "    def __init__(self, params:Params, I=13):\n",
    "        self.params = params\n",
    "        self.I = I\n",
    "    \n",
    "    def x1(self):\n",
    "        return multivariate_normal(self.params.pi.flatten(), self.params.Sigma).rvs(1)\n",
    "    \n",
    "    def train(self, log_returns, maxsteps=25, tol=0.01):\n",
    "        x_1 = self.x1()\n",
    "        self.params = em(x_1, log_returns, self.params, maxsteps=maxsteps, tol=tol)\n",
    "    \n",
    "    def predict(self, y_observed):\n",
    "        # This will return a vector of y_hat that is the same size as y_observed\n",
    "        # The assumption is we start at a hidden state x1 described by the distribution in self.params\n",
    "        N = y_observed.size\n",
    "        predictions = np.zeros_like(y_observed)\n",
    "        x_t = self.x1()\n",
    "        Sigma_t = self.params.Sigma\n",
    "        predictions[0] = (C@x_t)[0]\n",
    "        for i in range(1,N):\n",
    "            x_t, Sigma_t = kalman_filtering(i, x_t, y_t, Sigma_t, self.params)\n",
    "            predictions[i] = (C@x_plus)[0]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = em(x_1, ys[1:N_train*13], theta, maxsteps=25, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - undo this\n",
    "# It seems like the phi parameter converges to a wrong thing. If we use the guess of phi it works much better\n",
    "# WHY?\n",
    "test_params = Params(new_params.pi, new_params.Sigma, new_params.a_eta, new_params.a_mu,\n",
    "                     new_params.sigma_eta_sq, new_params.sigma_mu_sq, new_params.r, theta.phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e4e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = KalmanPredictor(test_params) # we already trained them in the previous cell, holdover from previous code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460536a",
   "metadata": {},
   "source": [
    "## Test Kalman filter with given params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df[\"Log_Turnover\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = df.iloc[0:1][\"Log_Turnover\"]\n",
    "x_t = np.reshape(np.array([y_t/2, y_t/2]), 2)\n",
    "xs = [x_t,]\n",
    "\n",
    "Sigma_t = np.identity(2)\n",
    "sigmas = [Sigma_t,]\n",
    "\n",
    "y_pred = [y_t]\n",
    "y_pred = predictor.predict(df[\"Log_Turnover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = [np.mean(np.square(y_pred[i] - df.iloc[i:i+1][\"Log_Turnover\"])) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = df.iloc[0:1][\"Log_Turnover\"]\n",
    "x_t = np.reshape(np.array([y_t/2, y_t/2]), 2)\n",
    "\n",
    "Sigma_t = np.identity(2)\n",
    "\n",
    "y_pred_new = [y_t]\n",
    "\n",
    "for i in range(N):\n",
    "    y_t = df.iloc[i:i+1][\"Log_Turnover\"]\n",
    "    x_plus, Sigma_plus = kalman_filtering(i, x_t, y_t, Sigma_t, test_params)\n",
    "    y_pred_new.append((C@x_plus)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_new = [np.mean(np.square(y_pred_new[i] - df.iloc[i:i+1][\"Log_Turnover\"])) for i in range(N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce86eb",
   "metadata": {},
   "source": [
    "### Comparison: hourly average over the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_avgs = np.log(df[\"Hourly averages\"])\n",
    "errs_avg = [np.mean(np.square(log_avgs - df.iloc[i:i+1][\"Log_Turnover\"])) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2de626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.semilogy(np.mean(np.reshape(errs, (int(len(errs)/I), I)), axis=1), label=\"Average daily prediction error\")\n",
    "plt.xlabel(\"Day of year\"); plt.ylabel(\"MSE error\")\n",
    "plt.semilogy(np.mean(np.reshape(errs_new, (int(len(errs_new)/I), I)), axis=1), label=\"Daily prediction error (Kalman)\")\n",
    "plt.semilogy(np.mean(np.reshape(errs_avg, (int(len(errs_avg)/I), I)), axis=1), linestyle=\"--\", label=\"Daily prediction error (average)\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"kalman_errors_year.pdf\")\n",
    "print(\"Average error: {}\".format(np.mean(errs_avg)))\n",
    "print(\"Kalman error: {}\".format(np.mean(errs_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, sharex=True, figsize=(5,7))\n",
    "\n",
    "axs[0].semilogy(np.exp(y_pred_new[-I:]),label=\"Predicted turnover (Kalman)\", linestyle=\"-.\", color=\"cornflowerblue\")\n",
    "axs[0].plot(np.exp(df.iloc[-I:][\"Log_Turnover\"].to_numpy()), label=\"True normalized turnover\", color=\"black\")\n",
    "axs[0].plot(df.iloc[-I:][\"Hourly averages\"].to_numpy(), label=\"Predicted turnover (mean)\", color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "for i in range(1,5):\n",
    "    axs[i].semilogy(np.exp(y_pred_new[-I*(i+1):-I*i]), linestyle=\"-.\", color=\"cornflowerblue\")\n",
    "    axs[i].plot(np.exp(df.iloc[-(i+1)*I:-i*I][\"Log_Turnover\"].to_numpy()), color=\"black\")\n",
    "    axs[i].plot(df.iloc[-(i+1)*I:-i*I][\"Hourly averages\"].to_numpy(), color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "daily_labels = [\"9:30\", \"10:30\", \"11:30\", \"12:30\", \"13:30\", \"14:30\", \"15:30\",]\n",
    "plt.xticks(ticks=range(0, I, 2), labels=daily_labels)\n",
    "fig.legend(loc=\"upper center\"); plt.ylabel(\"Normalized turnover\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"kalman_prediction.pdf\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
