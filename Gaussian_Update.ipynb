{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/TAQ_15Min_AAPL_2023.csv\")\n",
    "df.index = df.datetime\n",
    "N_day = 26\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_volumes(mu, Sigma, true_volumes):\n",
    "    \"\"\"\n",
    "    param mu: means\n",
    "    param Sigma: covariance\n",
    "    param true_volumes: true volumes, i.e., means[0] predicts true_volumes[0]\n",
    "    \"\"\"\n",
    "    n= mu.shape[0]\n",
    "    \n",
    "    predictions = np.zeros(n)\n",
    "    predictions[0] = mu[0]\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        ### following Wikipedia's notation, we observe x2 and update x1\n",
    "        \n",
    "        mu1 = mu[i:]\n",
    "        mu2 = mu[:i]\n",
    "        a = true_volumes[:i]\n",
    "        \n",
    "        mu_bar = mu[i:]\n",
    "        Sigma_12 = Sigma[i:, :i]\n",
    "        Sigma_22 = Sigma[:i, :i]\n",
    "        Sigma_21 = Sigma[:i, i:]\n",
    "#         assert Sigma_21 == Sigma_12.T\n",
    "\n",
    "        mu_bar = mu1 + Sigma_12 @ np.linalg.inv(Sigma_22) @ (a-mu2)\n",
    "        \n",
    "        predictions[i] = mu_bar[0]\n",
    "    \n",
    "    return predictions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.index = pd.to_datetime(X1.index)\n",
    "grouped = X1.groupby(pd.Grouper(freq='1d'))\n",
    "bad_ts = []\n",
    "for (t,g) in grouped:\n",
    "    if g.shape[0] == N_day or g.shape[0] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Bad timestamp: {} has size {}\".format(t, g.shape[0]))\n",
    "        bad_ts.append(t)\n",
    "\n",
    "# Delete the days that have truncated data\n",
    "for bad_t in bad_ts:\n",
    "    nxt = pd.Timestamp(year=bad_t.year, month=bad_t.month, day=bad_t.day+1)\n",
    "    X1 = X1[~(X1.index < nxt) & (X1.index > bad_t)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pd.DataFrame(df[\"VOLUME\"]).shape[0]\n",
    "X = pd.DataFrame(df[\"VOLUME\"]).to_numpy().reshape(int(N/N_day), N_day)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_col(pd_col, i):\n",
    "    d = {\"VOLUME\" : \"VOLUME_{}\".format(N_day-i)}\n",
    "    pd_col.rename(columns=d, inplace=True)\n",
    "    return pd_col.shift(-i)[:-N_day-1]\n",
    "\n",
    "#X1 = pd.concat([lag_col(pd.DataFrame(df[\"VOLUME\"]), i) for i in range(N_day)], axis=1)\n",
    "#X = X1.to_numpy() # this constructs a lagged matrix but I don't know why this makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ae6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "A = np.random.normal(size=(N_day,N_day))\n",
    "\n",
    "Sigma = A@A.T\n",
    "\n",
    "#X = np.random.multivariate_normal(np.zeros(10),Sigma, 1000)\n",
    "\n",
    "mu = X.mean(axis=0)\n",
    "\n",
    "benchmark_error = ((X-mu)**2).mean()\n",
    "# so we would do N_day-1 updates per row since we have N_day columns \n",
    "\n",
    "mu = X.mean(axis=0)\n",
    "Sigma = np.cov(X[:-1].T)\n",
    "true_volumes = X[-1]\n",
    "\n",
    "pred = predict_volumes(mu, Sigma, true_volumes)\n",
    "print(f\"MSE without mean update: {((mu-true_volumes)**2).mean()}\")\n",
    "print(f\"MSE with mean update: {((pred-true_volumes)**2).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0dab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(range(N_day), pred, label=\"Predicted\", linestyle=\"dashed\")\n",
    "plt.semilogy(range(-N_day,1), X1[\"VOLUME_1\"][-N_day*2:-N_day+1], label=\"Last {} of data\".format(N_day), color=\"black\")\n",
    "plt.semilogy(range(N_day), true_volumes, label=\"True\", color=\"blue\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a32464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
