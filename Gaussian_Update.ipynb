{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef247f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/TAQ_15Min_AAPL_2023.csv\")\n",
    "df.index = df.datetime\n",
    "N_day = 26\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_volumes(mu, Sigma, true_volumes):\n",
    "    \"\"\"\n",
    "    param mu: means\n",
    "    param Sigma: covariance\n",
    "    param true_volumes: true volumes, i.e., means[0] predicts true_volumes[0]\n",
    "    \"\"\"\n",
    "    n= mu.shape[0]\n",
    "    \n",
    "    predictions = np.zeros(n)\n",
    "    predictions[0] = mu[0]\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        ### following Wikipedia's notation, we observe x2 and update x1\n",
    "        \n",
    "        mu1 = mu[i:]\n",
    "        mu2 = mu[:i]\n",
    "        a = true_volumes[:i]\n",
    "        \n",
    "        mu_bar = mu[i:]\n",
    "        Sigma_12 = Sigma[i:, :i]\n",
    "        Sigma_22 = Sigma[:i, :i]\n",
    "        Sigma_21 = Sigma[:i, i:]\n",
    "#         assert Sigma_21 == Sigma_12.T\n",
    "\n",
    "        mu_bar = mu1 + Sigma_12 @ np.linalg.inv(Sigma_22) @ (a-mu2)\n",
    "        \n",
    "        predictions[i] = mu_bar[0]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9bf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(df[\"VOLUME\"])\n",
    "X1.index = pd.to_datetime(X1.index)\n",
    "grouped = X1.groupby(pd.Grouper(freq='1d'))\n",
    "\n",
    "bad_ts = []\n",
    "to_remove = [pd.Timestamp(\"2023-07-03\"), pd.Timestamp(\"2023-11-24\"), pd.Timestamp(\"2023-12-24\"), pd.Timestamp(\"2023-12-31\")]\n",
    "\n",
    "for (t,g) in grouped:\n",
    "    # This removes any days where the exchange closes early, and the days listed in to_remove\n",
    "    # note that this is necessary because while some of these outlier days have truncated data, others don't\n",
    "    # so we can't just detect and drop truncated data\n",
    "    if (g.shape[0] != N_day and g.shape[0] != 0) or (t in to_remove):\n",
    "        print(\"Bad timestamp: {} has size {}\".format(t, g.shape[0]))\n",
    "        bad_ts.append(t)\n",
    "\n",
    "# Delete the days that have truncated data\n",
    "for bad_t in bad_ts:\n",
    "    nxt = pd.Timestamp(year=bad_t.year, month=bad_t.month, day=bad_t.day+1)\n",
    "    X1 = X1[~((X1.index < nxt) & (X1.index > bad_t))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X1.shape[0]\n",
    "X = X1.to_numpy().reshape(int(N/N_day), N_day)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270591ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def lag_col(pd_col, i):\n",
    "#    d = {\"VOLUME\" : \"VOLUME_{}\".format(N_day-i)}\n",
    "#    pd_col.rename(columns=d, inplace=True)\n",
    "#    return pd_col.shift(-i)[:-N_day-1]\n",
    "\n",
    "#X1 = pd.concat([lag_col(pd.DataFrame(df[\"VOLUME\"]), i) for i in range(N_day)], axis=1)\n",
    "#X = X1.to_numpy() # this constructs a lagged matrix but I don't know why this makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(0)\n",
    "def train_and_predict(X):\n",
    "    A = np.random.normal(size=(N_day,N_day))\n",
    "\n",
    "    Sigma = A@A.T\n",
    "\n",
    "    mu = X.mean(axis=0)\n",
    "\n",
    "    benchmark_error = ((X-mu)**2).mean()\n",
    "    # so we would do N_day-1 updates per row since we have N_day columns \n",
    "\n",
    "    mu = X.mean(axis=0)\n",
    "    Sigma = np.cov(X[:-1].T)\n",
    "    true_volumes = X[-1]\n",
    "\n",
    "    pred = predict_volumes(mu, Sigma, true_volumes)\n",
    "    return mu, pred, true_volumes\n",
    "\n",
    "mu, pred, true_volumes = train_and_predict(X)\n",
    "print(f\"MSE percent without mean update: {(((mu-true_volumes)/true_volumes)**2).mean()}\")\n",
    "print(f\"MSE percent with mean update: {(((pred-true_volumes)/true_volumes)**2).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(range(N_day), pred, label=\"Predicted\", linestyle=\"dashed\")\n",
    "plt.semilogy(range(N_day), true_volumes, label=\"True\", color=\"blue\")\n",
    "\n",
    "daily_labels = [\"9:30\", \"10:30\", \"11:30\", \"12:30\", \"1:30\", \"2:30\", \"3:30\"]\n",
    "plt.xticks(ticks=range(0, 26, 4), labels=daily_labels)\n",
    "plt.legend(); plt.ylabel(\"Volume (# shares)\")\n",
    "plt.savefig(\"prediction.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29507e",
   "metadata": {},
   "source": [
    "## Visualization of data\n",
    "This isn't any type of analysis, it's just a good plot for our presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c0418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in range(X.shape[0]):\n",
    "#    plt.semilogy(X[d,:], linewidth=0.5, color=\"cornflowerblue\")\n",
    "\n",
    "#plt.xticks(ticks=range(0, 26, 4), labels=daily_labels)\n",
    "#plt.ylabel(\"Volume (# shares)\")\n",
    "#plt.title(\"Intraday volume for AAPL over 2023-2024\")\n",
    "#plt.savefig(\"data_visualization.pdf\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59692ef",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "(evaluate how adding more rows of data improves the MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520363ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 250\n",
    "errors = np.zeros(T - N_day)\n",
    "errors_mean = np.zeros(T - N_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does a sort of rolling test where we start at N_day rows and as the year progresses, we add more rows\n",
    "for d in range(N_day, T):\n",
    "    mu_d, pred_d, true_volumes_d = train_and_predict(X[0:d+1,:])\n",
    "    errors_mean[d-N_day] = (((mu_d    - true_volumes_d)/true_volumes_d)**2).mean()\n",
    "    errors[d-N_day]      = (((pred_d - true_volumes_d)/true_volumes_d)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e402fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(N_day, T), errors_mean, label=\"Naive (mean as prediction)\")\n",
    "plt.plot(range(N_day, T), errors, label=\"Gaussian prediction\")\n",
    "plt.xlabel(\"Day of year\"); plt.ylabel(\"Percent error\")\n",
    "plt.legend()\n",
    "plt.savefig(\"gaussian_errors_year.pdf\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
